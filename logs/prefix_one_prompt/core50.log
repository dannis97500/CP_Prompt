nohup: ignoring input
./logs/prefix_one_prompt_vit_query_core50_50_2023-11-09-23:06:48
2023-11-09 23:06:48,242 [trainer.py] => config: configs/1prefix_one_prompt/prefix_prompt_length/core50/14.json
2023-11-09 23:06:48,242 [trainer.py] => prefix: prefix_one_prompt
2023-11-09 23:06:48,242 [trainer.py] => dataset: core50
2023-11-09 23:06:48,242 [trainer.py] => data_path: /home/aa/cp_prompt/data/core50_128x128
2023-11-09 23:06:48,242 [trainer.py] => task_name: ['s1', 's2', 's4', 's5', 's6', 's8', 's9', 's11']
2023-11-09 23:06:48,242 [trainer.py] => knn_k: 5
2023-11-09 23:06:48,242 [trainer.py] => prefix_tuning: keqv
2023-11-09 23:06:48,242 [trainer.py] => is_fix_share_prompt: True
2023-11-09 23:06:48,242 [trainer.py] => memory_size: 0
2023-11-09 23:06:48,242 [trainer.py] => memory_per_class: 0
2023-11-09 23:06:48,242 [trainer.py] => fixed_memory: True
2023-11-09 23:06:48,242 [trainer.py] => shuffle: False
2023-11-09 23:06:48,243 [trainer.py] => init_cls: 50
2023-11-09 23:06:48,243 [trainer.py] => increment: 50
2023-11-09 23:06:48,243 [trainer.py] => model_name: prefix_one_prompt
2023-11-09 23:06:48,243 [trainer.py] => query_type: vit_query
2023-11-09 23:06:48,243 [trainer.py] => embd_dim: 768
2023-11-09 23:06:48,243 [trainer.py] => share_prompt_length: 4
2023-11-09 23:06:48,243 [trainer.py] => prefix_prompt_length: 14
2023-11-09 23:06:48,243 [trainer.py] => prefix_prompt_layers: [0, 9, 10]
2023-11-09 23:06:48,243 [trainer.py] => total_sessions: 8
2023-11-09 23:06:48,243 [trainer.py] => device: [device(type='cuda', index=5)]
2023-11-09 23:06:48,243 [trainer.py] => seed: 1993
2023-11-09 23:06:48,243 [trainer.py] => EPSILON: 1e-08
2023-11-09 23:06:48,243 [trainer.py] => init_epoch: 20
2023-11-09 23:06:48,243 [trainer.py] => init_lr: 0.01
2023-11-09 23:06:48,243 [trainer.py] => init_lr_decay: 0.1
2023-11-09 23:06:48,243 [trainer.py] => init_milestones: [20, 30, 40]
2023-11-09 23:06:48,243 [trainer.py] => init_weight_decay: 0.0005
2023-11-09 23:06:48,243 [trainer.py] => epochs: 20
2023-11-09 23:06:48,243 [trainer.py] => lrate: 0.01
2023-11-09 23:06:48,243 [trainer.py] => lrate_decay: 0.1
2023-11-09 23:06:48,243 [trainer.py] => milestones: [20, 30]
2023-11-09 23:06:48,243 [trainer.py] => batch_size: 128
2023-11-09 23:06:48,243 [trainer.py] => weight_decay: 0.0002
2023-11-09 23:06:48,243 [trainer.py] => num_workers: 16
Loading paths...
Loading LUP...
Loading labels...
Loading data...
Loading data...
Loading data...
Loading data...
Loading data...
Loading data...
Loading data...
Loading data...
2023-11-09 23:13:32,324 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399]
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
2023-11-09 23:13:41,699 [trainer.py] => All params: 149947393
2023-11-09 23:13:41,701 [trainer.py] => Trainable params: 149947393
2023-11-09 23:13:41,701 [prefix_prompt_tuning.py] => Learning on 0-50
/vepfs/aminer_rec/algorithm/domain_increment/utils/data.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  train_x = np.concatenate(np.array(dataset_list)[:, 0])
/vepfs/aminer_rec/algorithm/domain_increment/utils/data.py:103: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  train_y = np.concatenate(np.array(dataset_list)[:, 1])
Parameters to be updated: {'share_prompt.weight', 'prefix_prompt.e_p_10', 'classifier_pool.0.ctx', 'prefix_prompt.e_p_0', 'prefix_prompt.e_p_9'},count:269312

  0%|          | 0/20 [00:00<?, ?it/s]
Task 0, Epoch 1/20 => Loss 2.074, Train_accy 21.35, Test_accy 31.54:   0%|          | 0/20 [02:41<?, ?it/s]
Task 0, Epoch 1/20 => Loss 2.074, Train_accy 21.35, Test_accy 31.54:   5%|▌         | 1/20 [02:41<51:12, 161.71s/it]
Task 0, Epoch 2/20 => Loss 1.371, Train_accy 54.30, Test_accy 72.49:   5%|▌         | 1/20 [05:20<51:12, 161.71s/it]
Task 0, Epoch 2/20 => Loss 1.371, Train_accy 54.30, Test_accy 72.49:  10%|█         | 2/20 [05:20<48:01, 160.08s/it]
Task 0, Epoch 3/20 => Loss 0.662, Train_accy 80.82, Test_accy 83.64:  10%|█         | 2/20 [07:55<48:01, 160.08s/it]
Task 0, Epoch 3/20 => Loss 0.662, Train_accy 80.82, Test_accy 83.64:  15%|█▌        | 3/20 [07:55<44:37, 157.47s/it]
Task 0, Epoch 4/20 => Loss 0.518, Train_accy 85.46, Test_accy 85.79:  15%|█▌        | 3/20 [10:31<44:37, 157.47s/it]
Task 0, Epoch 4/20 => Loss 0.518, Train_accy 85.46, Test_accy 85.79:  20%|██        | 4/20 [10:31<41:51, 156.95s/it]
Task 0, Epoch 5/20 => Loss 0.457, Train_accy 87.21, Test_accy 86.71:  20%|██        | 4/20 [13:05<41:51, 156.95s/it]
Task 0, Epoch 5/20 => Loss 0.457, Train_accy 87.21, Test_accy 86.71:  25%|██▌       | 5/20 [13:05<39:01, 156.07s/it]
Task 0, Epoch 6/20 => Loss 0.392, Train_accy 88.95, Test_accy 86.67:  25%|██▌       | 5/20 [15:41<39:01, 156.07s/it]
Task 0, Epoch 6/20 => Loss 0.392, Train_accy 88.95, Test_accy 86.67:  30%|███       | 6/20 [15:41<36:21, 155.84s/it]
Task 0, Epoch 7/20 => Loss 0.360, Train_accy 89.82, Test_accy 87.85:  30%|███       | 6/20 [18:12<36:21, 155.84s/it]
Task 0, Epoch 7/20 => Loss 0.360, Train_accy 89.82, Test_accy 87.85:  35%|███▌      | 7/20 [18:12<33:25, 154.29s/it]
Task 0, Epoch 8/20 => Loss 0.359, Train_accy 89.93, Test_accy 86.19:  35%|███▌      | 7/20 [20:44<33:25, 154.29s/it]
Task 0, Epoch 8/20 => Loss 0.359, Train_accy 89.93, Test_accy 86.19:  40%|████      | 8/20 [20:44<30:45, 153.79s/it]
Task 0, Epoch 9/20 => Loss 0.318, Train_accy 90.87, Test_accy 86.87:  40%|████      | 8/20 [23:16<30:45, 153.79s/it]
Task 0, Epoch 9/20 => Loss 0.318, Train_accy 90.87, Test_accy 86.87:  45%|████▌     | 9/20 [23:16<28:03, 153.03s/it]
Task 0, Epoch 10/20 => Loss 0.310, Train_accy 91.33, Test_accy 87.71:  45%|████▌     | 9/20 [25:46<28:03, 153.03s/it]
Task 0, Epoch 10/20 => Loss 0.310, Train_accy 91.33, Test_accy 87.71:  50%|█████     | 10/20 [25:46<25:20, 152.07s/it]
Task 0, Epoch 11/20 => Loss 0.289, Train_accy 91.92, Test_accy 86.90:  50%|█████     | 10/20 [28:18<25:20, 152.07s/it]
Task 0, Epoch 11/20 => Loss 0.289, Train_accy 91.92, Test_accy 86.90:  55%|█████▌    | 11/20 [28:18<22:48, 152.04s/it]
Task 0, Epoch 12/20 => Loss 0.278, Train_accy 92.22, Test_accy 88.42:  55%|█████▌    | 11/20 [30:50<22:48, 152.04s/it]
Task 0, Epoch 12/20 => Loss 0.278, Train_accy 92.22, Test_accy 88.42:  60%|██████    | 12/20 [30:50<20:16, 152.01s/it]
Task 0, Epoch 13/20 => Loss 0.275, Train_accy 92.34, Test_accy 86.42:  60%|██████    | 12/20 [33:17<20:16, 152.01s/it]
Task 0, Epoch 13/20 => Loss 0.275, Train_accy 92.34, Test_accy 86.42:  65%|██████▌   | 13/20 [33:17<17:35, 150.74s/it]
Task 0, Epoch 14/20 => Loss 0.267, Train_accy 92.44, Test_accy 87.62:  65%|██████▌   | 13/20 [35:50<17:35, 150.74s/it]
Task 0, Epoch 14/20 => Loss 0.267, Train_accy 92.44, Test_accy 87.62:  70%|███████   | 14/20 [35:50<15:07, 151.33s/it]
Task 0, Epoch 15/20 => Loss 0.266, Train_accy 92.57, Test_accy 87.04:  70%|███████   | 14/20 [38:21<15:07, 151.33s/it]
Task 0, Epoch 15/20 => Loss 0.266, Train_accy 92.57, Test_accy 87.04:  75%|███████▌  | 15/20 [38:21<12:36, 151.29s/it]
Task 0, Epoch 16/20 => Loss 0.242, Train_accy 93.14, Test_accy 87.74:  75%|███████▌  | 15/20 [40:51<12:36, 151.29s/it]
Task 0, Epoch 16/20 => Loss 0.242, Train_accy 93.14, Test_accy 87.74:  80%|████████  | 16/20 [40:51<10:03, 150.94s/it]
Task 0, Epoch 17/20 => Loss 0.241, Train_accy 93.27, Test_accy 87.07:  80%|████████  | 16/20 [43:24<10:03, 150.94s/it]
Task 0, Epoch 17/20 => Loss 0.241, Train_accy 93.27, Test_accy 87.07:  85%|████████▌ | 17/20 [43:24<07:34, 151.47s/it]
Task 0, Epoch 18/20 => Loss 0.237, Train_accy 93.22, Test_accy 87.75:  85%|████████▌ | 17/20 [45:58<07:34, 151.47s/it]
Task 0, Epoch 18/20 => Loss 0.237, Train_accy 93.22, Test_accy 87.75:  90%|█████████ | 18/20 [45:58<05:04, 152.18s/it]
Task 0, Epoch 19/20 => Loss 0.229, Train_accy 93.54, Test_accy 87.59:  90%|█████████ | 18/20 [48:29<05:04, 152.18s/it]
Task 0, Epoch 19/20 => Loss 0.229, Train_accy 93.54, Test_accy 87.59:  95%|█████████▌| 19/20 [48:29<02:31, 151.97s/it]
Task 0, Epoch 20/20 => Loss 0.230, Train_accy 93.60, Test_accy 87.53:  95%|█████████▌| 19/20 [51:02<02:31, 151.97s/it]
Task 0, Epoch 20/20 => Loss 0.230, Train_accy 93.60, Test_accy 87.53: 100%|██████████| 20/20 [51:02<00:00, 152.11s/it]
Task 0, Epoch 20/20 => Loss 0.230, Train_accy 93.60, Test_accy 87.53: 100%|██████████| 20/20 [51:02<00:00, 153.12s/it]2023-11-10 00:04:58,355 [prefix_prompt_tuning.py] => Task 0, Epoch 20/20 => Loss 0.230, Train_accy 93.60, Test_accy 87.53

2023-11-10 00:08:56,279 [trainer.py] => CNN: {'total': 87.53, '00-49': 87.53, 'old': 0, 'new': 87.53}
2023-11-10 00:08:56,279 [trainer.py] => CNN top1 curve: [87.53]
2023-11-10 00:08:56,281 [trainer.py] => All params: 149947393
2023-11-10 00:08:56,282 [trainer.py] => Trainable params: 269312
2023-11-10 00:08:56,283 [prefix_prompt_tuning.py] => Learning on 50-100
Parameters to be updated: {'share_prompt.weight', 'classifier_pool.1.ctx', 'prefix_prompt.e_p_10', 'prefix_prompt.e_p_0', 'prefix_prompt.e_p_9'},count:269312

  0%|          | 0/20 [00:00<?, ?it/s]
Task 1, Epoch 1/20 => Loss 1.875, Train_accy 31.06, Test_accy 51.49:   0%|          | 0/20 [02:30<?, ?it/s]
Task 1, Epoch 1/20 => Loss 1.875, Train_accy 31.06, Test_accy 51.49:   5%|▌         | 1/20 [02:30<47:30, 150.05s/it]
Task 1, Epoch 2/20 => Loss 0.836, Train_accy 75.71, Test_accy 75.60:   5%|▌         | 1/20 [04:59<47:30, 150.05s/it]
Task 1, Epoch 2/20 => Loss 0.836, Train_accy 75.71, Test_accy 75.60:  10%|█         | 2/20 [04:59<44:56, 149.80s/it]
Task 1, Epoch 3/20 => Loss 0.507, Train_accy 86.27, Test_accy 77.38:  10%|█         | 2/20 [07:31<44:56, 149.80s/it]
Task 1, Epoch 3/20 => Loss 0.507, Train_accy 86.27, Test_accy 77.38:  15%|█▌        | 3/20 [07:31<42:42, 150.75s/it]
Task 1, Epoch 4/20 => Loss 0.410, Train_accy 88.99, Test_accy 79.42:  15%|█▌        | 3/20 [10:02<42:42, 150.75s/it]
Task 1, Epoch 4/20 => Loss 0.410, Train_accy 88.99, Test_accy 79.42:  20%|██        | 4/20 [10:02<40:13, 150.82s/it]
Task 1, Epoch 5/20 => Loss 0.380, Train_accy 89.76, Test_accy 83.24:  20%|██        | 4/20 [12:32<40:13, 150.82s/it]
Task 1, Epoch 5/20 => Loss 0.380, Train_accy 89.76, Test_accy 83.24:  25%|██▌       | 5/20 [12:32<37:36, 150.45s/it]
Task 1, Epoch 6/20 => Loss 0.344, Train_accy 90.56, Test_accy 83.19:  25%|██▌       | 5/20 [15:03<37:36, 150.45s/it]
Task 1, Epoch 6/20 => Loss 0.344, Train_accy 90.56, Test_accy 83.19:  30%|███       | 6/20 [15:03<35:10, 150.73s/it]
Task 1, Epoch 7/20 => Loss 0.309, Train_accy 91.74, Test_accy 83.92:  30%|███       | 6/20 [17:36<35:10, 150.73s/it]
Task 1, Epoch 7/20 => Loss 0.309, Train_accy 91.74, Test_accy 83.92:  35%|███▌      | 7/20 [17:36<32:48, 151.45s/it]
Task 1, Epoch 8/20 => Loss 0.314, Train_accy 91.38, Test_accy 81.57:  35%|███▌      | 7/20 [20:06<32:48, 151.45s/it]
Task 1, Epoch 8/20 => Loss 0.314, Train_accy 91.38, Test_accy 81.57:  40%|████      | 8/20 [20:06<30:13, 151.11s/it]
Task 1, Epoch 9/20 => Loss 0.312, Train_accy 91.42, Test_accy 83.06:  40%|████      | 8/20 [22:36<30:13, 151.11s/it]
Task 1, Epoch 9/20 => Loss 0.312, Train_accy 91.42, Test_accy 83.06:  45%|████▌     | 9/20 [22:36<27:38, 150.73s/it]
Task 1, Epoch 10/20 => Loss 0.292, Train_accy 91.90, Test_accy 82.81:  45%|████▌     | 9/20 [25:05<27:38, 150.73s/it]
Task 1, Epoch 10/20 => Loss 0.292, Train_accy 91.90, Test_accy 82.81:  50%|█████     | 10/20 [25:05<25:01, 150.17s/it]
Task 1, Epoch 11/20 => Loss 0.279, Train_accy 92.28, Test_accy 84.45:  50%|█████     | 10/20 [27:37<25:01, 150.17s/it]
Task 1, Epoch 11/20 => Loss 0.279, Train_accy 92.28, Test_accy 84.45:  55%|█████▌    | 11/20 [27:37<22:35, 150.65s/it]
Task 1, Epoch 12/20 => Loss 0.264, Train_accy 92.78, Test_accy 82.72:  55%|█████▌    | 11/20 [30:06<22:35, 150.65s/it]
Task 1, Epoch 12/20 => Loss 0.264, Train_accy 92.78, Test_accy 82.72:  60%|██████    | 12/20 [30:06<20:02, 150.31s/it]
Task 1, Epoch 13/20 => Loss 0.237, Train_accy 93.30, Test_accy 84.42:  60%|██████    | 12/20 [32:38<20:02, 150.31s/it]
Task 1, Epoch 13/20 => Loss 0.237, Train_accy 93.30, Test_accy 84.42:  65%|██████▌   | 13/20 [32:38<17:34, 150.67s/it]
Task 1, Epoch 14/20 => Loss 0.264, Train_accy 92.80, Test_accy 85.25:  65%|██████▌   | 13/20 [35:08<17:34, 150.67s/it]
Task 1, Epoch 14/20 => Loss 0.264, Train_accy 92.80, Test_accy 85.25:  70%|███████   | 14/20 [35:08<15:03, 150.55s/it]
Task 1, Epoch 15/20 => Loss 0.239, Train_accy 93.22, Test_accy 84.98:  70%|███████   | 14/20 [37:40<15:03, 150.55s/it]
Task 1, Epoch 15/20 => Loss 0.239, Train_accy 93.22, Test_accy 84.98:  75%|███████▌  | 15/20 [37:40<12:34, 150.90s/it]
Task 1, Epoch 16/20 => Loss 0.233, Train_accy 93.56, Test_accy 84.63:  75%|███████▌  | 15/20 [40:11<12:34, 150.90s/it]
Task 1, Epoch 16/20 => Loss 0.233, Train_accy 93.56, Test_accy 84.63:  80%|████████  | 16/20 [40:11<10:03, 150.93s/it]
Task 1, Epoch 17/20 => Loss 0.229, Train_accy 93.56, Test_accy 84.89:  80%|████████  | 16/20 [42:41<10:03, 150.93s/it]
Task 1, Epoch 17/20 => Loss 0.229, Train_accy 93.56, Test_accy 84.89:  85%|████████▌ | 17/20 [42:41<07:31, 150.61s/it]
Task 1, Epoch 18/20 => Loss 0.227, Train_accy 93.62, Test_accy 85.12:  85%|████████▌ | 17/20 [45:13<07:31, 150.61s/it]
Task 1, Epoch 18/20 => Loss 0.227, Train_accy 93.62, Test_accy 85.12:  90%|█████████ | 18/20 [45:13<05:02, 151.01s/it]
Task 1, Epoch 19/20 => Loss 0.231, Train_accy 93.58, Test_accy 85.02:  90%|█████████ | 18/20 [47:42<05:02, 151.01s/it]
Task 1, Epoch 19/20 => Loss 0.231, Train_accy 93.58, Test_accy 85.02:  95%|█████████▌| 19/20 [47:42<02:30, 150.49s/it]
Task 1, Epoch 20/20 => Loss 0.220, Train_accy 93.88, Test_accy 85.12:  95%|█████████▌| 19/20 [50:13<02:30, 150.49s/it]
Task 1, Epoch 20/20 => Loss 0.220, Train_accy 93.88, Test_accy 85.12: 100%|██████████| 20/20 [50:13<00:00, 150.65s/it]
Task 1, Epoch 20/20 => Loss 0.220, Train_accy 93.88, Test_accy 85.12: 100%|██████████| 20/20 [50:13<00:00, 150.68s/it]2023-11-10 00:59:11,856 [prefix_prompt_tuning.py] => Task 1, Epoch 20/20 => Loss 0.220, Train_accy 93.88, Test_accy 85.12

2023-11-10 01:03:11,375 [trainer.py] => CNN: {'total': 87.06, '00-49': 87.06, 'old': 87.06, 'new': nan}
2023-11-10 01:03:11,375 [trainer.py] => CNN top1 curve: [87.53, 87.06]
2023-11-10 01:03:11,376 [trainer.py] => All params: 149947393
2023-11-10 01:03:11,377 [trainer.py] => Trainable params: 269312
2023-11-10 01:03:11,377 [prefix_prompt_tuning.py] => Learning on 100-150
/vepfs/aminer_rec/algorithm/domain_increment/utils/toolkit.py:84: RuntimeWarning: invalid value encountered in long_scalars
  all_acc['new'] = np.around(((y_pred[idxes]%class_num) == (y_true[idxes]%class_num)).sum()*100 / len(idxes), decimals=2)
Parameters to be updated: {'classifier_pool.2.ctx', 'share_prompt.weight', 'prefix_prompt.e_p_10', 'prefix_prompt.e_p_0', 'prefix_prompt.e_p_9'},count:269312

  0%|          | 0/20 [00:00<?, ?it/s]
Task 2, Epoch 1/20 => Loss 1.611, Train_accy 44.94, Test_accy 70.11:   0%|          | 0/20 [02:32<?, ?it/s]
Task 2, Epoch 1/20 => Loss 1.611, Train_accy 44.94, Test_accy 70.11:   5%|▌         | 1/20 [02:32<48:17, 152.52s/it]
Task 2, Epoch 2/20 => Loss 0.699, Train_accy 80.47, Test_accy 79.82:   5%|▌         | 1/20 [05:05<48:17, 152.52s/it]
Task 2, Epoch 2/20 => Loss 0.699, Train_accy 80.47, Test_accy 79.82:  10%|█         | 2/20 [05:05<45:48, 152.70s/it]
Task 2, Epoch 3/20 => Loss 0.527, Train_accy 85.75, Test_accy 81.51:  10%|█         | 2/20 [07:37<45:48, 152.70s/it]
Task 2, Epoch 3/20 => Loss 0.527, Train_accy 85.75, Test_accy 81.51:  15%|█▌        | 3/20 [07:37<43:09, 152.31s/it]
Task 2, Epoch 4/20 => Loss 0.480, Train_accy 87.19, Test_accy 83.02:  15%|█▌        | 3/20 [10:05<43:09, 152.31s/it]
Task 2, Epoch 4/20 => Loss 0.480, Train_accy 87.19, Test_accy 83.02:  20%|██        | 4/20 [10:05<40:12, 150.79s/it]
Task 2, Epoch 5/20 => Loss 0.454, Train_accy 87.72, Test_accy 85.41:  20%|██        | 4/20 [12:34<40:12, 150.79s/it]
Task 2, Epoch 5/20 => Loss 0.454, Train_accy 87.72, Test_accy 85.41:  25%|██▌       | 5/20 [12:34<37:31, 150.12s/it]
Task 2, Epoch 6/20 => Loss 0.424, Train_accy 88.62, Test_accy 83.55:  25%|██▌       | 5/20 [15:06<37:31, 150.12s/it]
Task 2, Epoch 6/20 => Loss 0.424, Train_accy 88.62, Test_accy 83.55:  30%|███       | 6/20 [15:06<35:07, 150.56s/it]
Task 2, Epoch 7/20 => Loss 0.407, Train_accy 88.92, Test_accy 85.37:  30%|███       | 6/20 [17:36<35:07, 150.56s/it]
Task 2, Epoch 7/20 => Loss 0.407, Train_accy 88.92, Test_accy 85.37:  35%|███▌      | 7/20 [17:36<32:39, 150.70s/it]
Task 2, Epoch 8/20 => Loss 0.372, Train_accy 89.76, Test_accy 85.76:  35%|███▌      | 7/20 [20:07<32:39, 150.70s/it]
Task 2, Epoch 8/20 => Loss 0.372, Train_accy 89.76, Test_accy 85.76:  40%|████      | 8/20 [20:07<30:07, 150.61s/it]
Task 2, Epoch 9/20 => Loss 0.381, Train_accy 89.60, Test_accy 86.36:  40%|████      | 8/20 [22:37<30:07, 150.61s/it]
Task 2, Epoch 9/20 => Loss 0.381, Train_accy 89.60, Test_accy 86.36:  45%|████▌     | 9/20 [22:37<27:35, 150.52s/it]
Task 2, Epoch 10/20 => Loss 0.356, Train_accy 90.27, Test_accy 85.86:  45%|████▌     | 9/20 [25:07<27:35, 150.52s/it]
Task 2, Epoch 10/20 => Loss 0.356, Train_accy 90.27, Test_accy 85.86:  50%|█████     | 10/20 [25:07<25:02, 150.28s/it]
Task 2, Epoch 11/20 => Loss 0.357, Train_accy 90.30, Test_accy 86.43:  50%|█████     | 10/20 [27:37<25:02, 150.28s/it]
Task 2, Epoch 11/20 => Loss 0.357, Train_accy 90.30, Test_accy 86.43:  55%|█████▌    | 11/20 [27:37<22:32, 150.25s/it]
Task 2, Epoch 12/20 => Loss 0.341, Train_accy 90.84, Test_accy 87.38:  55%|█████▌    | 11/20 [30:08<22:32, 150.25s/it]
Task 2, Epoch 12/20 => Loss 0.341, Train_accy 90.84, Test_accy 87.38:  60%|██████    | 12/20 [30:08<20:03, 150.46s/it]
Task 2, Epoch 13/20 => Loss 0.335, Train_accy 90.90, Test_accy 86.26:  60%|██████    | 12/20 [32:41<20:03, 150.46s/it]
Task 2, Epoch 13/20 => Loss 0.335, Train_accy 90.90, Test_accy 86.26:  65%|██████▌   | 13/20 [32:41<17:39, 151.29s/it]
Task 2, Epoch 14/20 => Loss 0.308, Train_accy 91.53, Test_accy 86.64:  65%|██████▌   | 13/20 [35:11<17:39, 151.29s/it]
Task 2, Epoch 14/20 => Loss 0.308, Train_accy 91.53, Test_accy 86.64:  70%|███████   | 14/20 [35:11<15:05, 150.93s/it]
Task 2, Epoch 15/20 => Loss 0.331, Train_accy 90.90, Test_accy 86.75:  70%|███████   | 14/20 [37:43<15:05, 150.93s/it]
Task 2, Epoch 15/20 => Loss 0.331, Train_accy 90.90, Test_accy 86.75:  75%|███████▌  | 15/20 [37:43<12:36, 151.21s/it]
Task 2, Epoch 16/20 => Loss 0.319, Train_accy 91.27, Test_accy 87.37:  75%|███████▌  | 15/20 [40:15<12:36, 151.21s/it]
Task 2, Epoch 16/20 => Loss 0.319, Train_accy 91.27, Test_accy 87.37:  80%|████████  | 16/20 [40:15<10:05, 151.25s/it]
Task 2, Epoch 17/20 => Loss 0.301, Train_accy 91.83, Test_accy 87.57:  80%|████████  | 16/20 [42:43<10:05, 151.25s/it]
Task 2, Epoch 17/20 => Loss 0.301, Train_accy 91.83, Test_accy 87.57:  85%|████████▌ | 17/20 [42:43<07:31, 150.41s/it]
Task 2, Epoch 18/20 => Loss 0.313, Train_accy 91.64, Test_accy 86.79:  85%|████████▌ | 17/20 [45:14<07:31, 150.41s/it]
Task 2, Epoch 18/20 => Loss 0.313, Train_accy 91.64, Test_accy 86.79:  90%|█████████ | 18/20 [45:14<05:01, 150.52s/it]
Task 2, Epoch 19/20 => Loss 0.287, Train_accy 92.20, Test_accy 87.11:  90%|█████████ | 18/20 [47:41<05:01, 150.52s/it]
Task 2, Epoch 19/20 => Loss 0.287, Train_accy 92.20, Test_accy 87.11:  95%|█████████▌| 19/20 [47:41<02:29, 149.63s/it]
Task 2, Epoch 20/20 => Loss 0.289, Train_accy 92.14, Test_accy 87.16:  95%|█████████▌| 19/20 [50:12<02:29, 149.63s/it]
Task 2, Epoch 20/20 => Loss 0.289, Train_accy 92.14, Test_accy 87.16: 100%|██████████| 20/20 [50:12<00:00, 149.85s/it]
Task 2, Epoch 20/20 => Loss 0.289, Train_accy 92.14, Test_accy 87.16: 100%|██████████| 20/20 [50:12<00:00, 150.61s/it]2023-11-10 01:53:25,353 [prefix_prompt_tuning.py] => Task 2, Epoch 20/20 => Loss 0.289, Train_accy 92.14, Test_accy 87.16

2023-11-10 01:57:30,201 [trainer.py] => CNN: {'total': 88.2, '00-49': 88.2, 'old': 88.2, 'new': nan}
2023-11-10 01:57:30,201 [trainer.py] => CNN top1 curve: [87.53, 87.06, 88.2]
2023-11-10 01:57:30,202 [trainer.py] => All params: 149947393
2023-11-10 01:57:30,203 [trainer.py] => Trainable params: 269312
2023-11-10 01:57:30,203 [prefix_prompt_tuning.py] => Learning on 150-200
/vepfs/aminer_rec/algorithm/domain_increment/utils/toolkit.py:84: RuntimeWarning: invalid value encountered in long_scalars
  all_acc['new'] = np.around(((y_pred[idxes]%class_num) == (y_true[idxes]%class_num)).sum()*100 / len(idxes), decimals=2)
Parameters to be updated: {'share_prompt.weight', 'prefix_prompt.e_p_10', 'prefix_prompt.e_p_0', 'classifier_pool.3.ctx', 'prefix_prompt.e_p_9'},count:269312

  0%|          | 0/20 [00:00<?, ?it/s]
Task 3, Epoch 1/20 => Loss 2.045, Train_accy 23.76, Test_accy 45.91:   0%|          | 0/20 [02:29<?, ?it/s]
Task 3, Epoch 1/20 => Loss 2.045, Train_accy 23.76, Test_accy 45.91:   5%|▌         | 1/20 [02:29<47:13, 149.15s/it]
Task 3, Epoch 2/20 => Loss 1.315, Train_accy 59.16, Test_accy 69.29:   5%|▌         | 1/20 [04:59<47:13, 149.15s/it]
Task 3, Epoch 2/20 => Loss 1.315, Train_accy 59.16, Test_accy 69.29:  10%|█         | 2/20 [04:59<44:55, 149.76s/it]
Task 3, Epoch 3/20 => Loss 0.839, Train_accy 76.24, Test_accy 80.03:  10%|█         | 2/20 [07:29<44:55, 149.76s/it]
Task 3, Epoch 3/20 => Loss 0.839, Train_accy 76.24, Test_accy 80.03:  15%|█▌        | 3/20 [07:29<42:29, 149.99s/it]
Task 3, Epoch 4/20 => Loss 0.693, Train_accy 80.95, Test_accy 77.95:  15%|█▌        | 3/20 [10:00<42:29, 149.99s/it]
Task 3, Epoch 4/20 => Loss 0.693, Train_accy 80.95, Test_accy 77.95:  20%|██        | 4/20 [10:00<40:06, 150.42s/it]
Task 3, Epoch 5/20 => Loss 0.635, Train_accy 82.15, Test_accy 85.46:  20%|██        | 4/20 [12:30<40:06, 150.42s/it]
Task 3, Epoch 5/20 => Loss 0.635, Train_accy 82.15, Test_accy 85.46:  25%|██▌       | 5/20 [12:30<37:34, 150.33s/it]
Task 3, Epoch 6/20 => Loss 0.577, Train_accy 84.61, Test_accy 85.66:  25%|██▌       | 5/20 [14:58<37:34, 150.33s/it]
Task 3, Epoch 6/20 => Loss 0.577, Train_accy 84.61, Test_accy 85.66:  30%|███       | 6/20 [14:58<34:53, 149.53s/it]
Task 3, Epoch 7/20 => Loss 0.541, Train_accy 85.39, Test_accy 86.28:  30%|███       | 6/20 [17:30<34:53, 149.53s/it]
Task 3, Epoch 7/20 => Loss 0.541, Train_accy 85.39, Test_accy 86.28:  35%|███▌      | 7/20 [17:30<32:32, 150.16s/it]
Task 3, Epoch 8/20 => Loss 0.528, Train_accy 85.63, Test_accy 86.98:  35%|███▌      | 7/20 [20:01<32:32, 150.16s/it]
Task 3, Epoch 8/20 => Loss 0.528, Train_accy 85.63, Test_accy 86.98:  40%|████      | 8/20 [20:01<30:05, 150.45s/it]
Task 3, Epoch 9/20 => Loss 0.498, Train_accy 86.56, Test_accy 85.58:  40%|████      | 8/20 [22:33<30:05, 150.45s/it]
Task 3, Epoch 9/20 => Loss 0.498, Train_accy 86.56, Test_accy 85.58:  45%|████▌     | 9/20 [22:33<27:40, 150.95s/it]
Task 3, Epoch 10/20 => Loss 0.453, Train_accy 87.70, Test_accy 87.83:  45%|████▌     | 9/20 [25:02<27:40, 150.95s/it]
Task 3, Epoch 10/20 => Loss 0.453, Train_accy 87.70, Test_accy 87.83:  50%|█████     | 10/20 [25:02<25:02, 150.26s/it]
Task 3, Epoch 11/20 => Loss 0.448, Train_accy 87.81, Test_accy 87.63:  50%|█████     | 10/20 [27:34<25:02, 150.26s/it]
Task 3, Epoch 11/20 => Loss 0.448, Train_accy 87.81, Test_accy 87.63:  55%|█████▌    | 11/20 [27:34<22:37, 150.89s/it]
Task 3, Epoch 12/20 => Loss 0.454, Train_accy 87.61, Test_accy 88.46:  55%|█████▌    | 11/20 [30:01<22:37, 150.89s/it]
Task 3, Epoch 12/20 => Loss 0.454, Train_accy 87.61, Test_accy 88.46:  60%|██████    | 12/20 [30:01<19:57, 149.72s/it]
Task 3, Epoch 13/20 => Loss 0.443, Train_accy 88.10, Test_accy 86.90:  60%|██████    | 12/20 [32:28<19:57, 149.72s/it]
Task 3, Epoch 13/20 => Loss 0.443, Train_accy 88.10, Test_accy 86.90:  65%|██████▌   | 13/20 [32:28<17:23, 149.03s/it]
Task 3, Epoch 14/20 => Loss 0.403, Train_accy 89.02, Test_accy 87.48:  65%|██████▌   | 13/20 [34:58<17:23, 149.03s/it]
Task 3, Epoch 14/20 => Loss 0.403, Train_accy 89.02, Test_accy 87.48:  70%|███████   | 14/20 [34:58<14:55, 149.31s/it]
Task 3, Epoch 15/20 => Loss 0.415, Train_accy 88.78, Test_accy 86.46:  70%|███████   | 14/20 [37:27<14:55, 149.31s/it]
Task 3, Epoch 15/20 => Loss 0.415, Train_accy 88.78, Test_accy 86.46:  75%|███████▌  | 15/20 [37:27<12:25, 149.10s/it]
Task 3, Epoch 16/20 => Loss 0.411, Train_accy 88.60, Test_accy 87.56:  75%|███████▌  | 15/20 [39:58<12:25, 149.10s/it]
Task 3, Epoch 16/20 => Loss 0.411, Train_accy 88.60, Test_accy 87.56:  80%|████████  | 16/20 [39:58<09:58, 149.73s/it]
Task 3, Epoch 17/20 => Loss 0.389, Train_accy 89.38, Test_accy 88.55:  80%|████████  | 16/20 [42:28<09:58, 149.73s/it]
Task 3, Epoch 17/20 => Loss 0.389, Train_accy 89.38, Test_accy 88.55:  85%|████████▌ | 17/20 [42:28<07:29, 149.71s/it]
Task 3, Epoch 18/20 => Loss 0.379, Train_accy 89.54, Test_accy 88.23:  85%|████████▌ | 17/20 [44:56<07:29, 149.71s/it]
Task 3, Epoch 18/20 => Loss 0.379, Train_accy 89.54, Test_accy 88.23:  90%|█████████ | 18/20 [44:56<04:58, 149.16s/it]
Task 3, Epoch 19/20 => Loss 0.400, Train_accy 89.40, Test_accy 88.37:  90%|█████████ | 18/20 [47:28<04:58, 149.16s/it]
Task 3, Epoch 19/20 => Loss 0.400, Train_accy 89.40, Test_accy 88.37:  95%|█████████▌| 19/20 [47:28<02:30, 150.03s/it]
Task 3, Epoch 20/20 => Loss 0.379, Train_accy 89.70, Test_accy 88.41:  95%|█████████▌| 19/20 [49:57<02:30, 150.03s/it]
Task 3, Epoch 20/20 => Loss 0.379, Train_accy 89.70, Test_accy 88.41: 100%|██████████| 20/20 [49:57<00:00, 149.92s/it]
Task 3, Epoch 20/20 => Loss 0.379, Train_accy 89.70, Test_accy 88.41: 100%|██████████| 20/20 [49:57<00:00, 149.90s/it]2023-11-10 02:47:29,998 [prefix_prompt_tuning.py] => Task 3, Epoch 20/20 => Loss 0.379, Train_accy 89.70, Test_accy 88.41

2023-11-10 02:51:26,647 [trainer.py] => CNN: {'total': 88.19, '00-49': 88.19, 'old': 88.19, 'new': nan}
2023-11-10 02:51:26,647 [trainer.py] => CNN top1 curve: [87.53, 87.06, 88.2, 88.19]
2023-11-10 02:51:26,648 [trainer.py] => All params: 149947393
2023-11-10 02:51:26,649 [trainer.py] => Trainable params: 269312
2023-11-10 02:51:26,649 [prefix_prompt_tuning.py] => Learning on 200-250
/vepfs/aminer_rec/algorithm/domain_increment/utils/toolkit.py:84: RuntimeWarning: invalid value encountered in long_scalars
  all_acc['new'] = np.around(((y_pred[idxes]%class_num) == (y_true[idxes]%class_num)).sum()*100 / len(idxes), decimals=2)
Parameters to be updated: {'classifier_pool.4.ctx', 'share_prompt.weight', 'prefix_prompt.e_p_10', 'prefix_prompt.e_p_0', 'prefix_prompt.e_p_9'},count:269312

  0%|          | 0/20 [00:00<?, ?it/s]
Task 4, Epoch 1/20 => Loss 1.583, Train_accy 43.16, Test_accy 66.17:   0%|          | 0/20 [02:27<?, ?it/s]
Task 4, Epoch 1/20 => Loss 1.583, Train_accy 43.16, Test_accy 66.17:   5%|▌         | 1/20 [02:27<46:50, 147.92s/it]
Task 4, Epoch 2/20 => Loss 0.649, Train_accy 81.61, Test_accy 80.94:   5%|▌         | 1/20 [04:54<46:50, 147.92s/it]
Task 4, Epoch 2/20 => Loss 0.649, Train_accy 81.61, Test_accy 80.94:  10%|█         | 2/20 [04:54<44:13, 147.42s/it]
Task 4, Epoch 3/20 => Loss 0.439, Train_accy 87.79, Test_accy 82.66:  10%|█         | 2/20 [07:21<44:13, 147.42s/it]
Task 4, Epoch 3/20 => Loss 0.439, Train_accy 87.79, Test_accy 82.66:  15%|█▌        | 3/20 [07:21<41:41, 147.15s/it]
Task 4, Epoch 4/20 => Loss 0.403, Train_accy 88.69, Test_accy 85.78:  15%|█▌        | 3/20 [09:49<41:41, 147.15s/it]
Task 4, Epoch 4/20 => Loss 0.403, Train_accy 88.69, Test_accy 85.78:  20%|██        | 4/20 [09:49<39:20, 147.55s/it]
Task 4, Epoch 5/20 => Loss 0.346, Train_accy 90.27, Test_accy 86.31:  20%|██        | 4/20 [12:20<39:20, 147.55s/it]
Task 4, Epoch 5/20 => Loss 0.346, Train_accy 90.27, Test_accy 86.31:  25%|██▌       | 5/20 [12:20<37:10, 148.72s/it]
Task 4, Epoch 6/20 => Loss 0.317, Train_accy 90.81, Test_accy 85.72:  25%|██▌       | 5/20 [14:54<37:10, 148.72s/it]
Task 4, Epoch 6/20 => Loss 0.317, Train_accy 90.81, Test_accy 85.72:  30%|███       | 6/20 [14:54<35:04, 150.34s/it]
Task 4, Epoch 7/20 => Loss 0.319, Train_accy 91.05, Test_accy 85.91:  30%|███       | 6/20 [17:29<35:04, 150.34s/it]
Task 4, Epoch 7/20 => Loss 0.319, Train_accy 91.05, Test_accy 85.91:  35%|███▌      | 7/20 [17:29<32:56, 152.04s/it]
Task 4, Epoch 8/20 => Loss 0.291, Train_accy 91.87, Test_accy 86.99:  35%|███▌      | 7/20 [20:02<32:56, 152.04s/it]
Task 4, Epoch 8/20 => Loss 0.291, Train_accy 91.87, Test_accy 86.99:  40%|████      | 8/20 [20:02<30:25, 152.14s/it]
Task 4, Epoch 9/20 => Loss 0.277, Train_accy 92.36, Test_accy 86.94:  40%|████      | 8/20 [22:32<30:25, 152.14s/it]
Task 4, Epoch 9/20 => Loss 0.277, Train_accy 92.36, Test_accy 86.94:  45%|████▌     | 9/20 [22:32<27:47, 151.55s/it]
Task 4, Epoch 10/20 => Loss 0.272, Train_accy 92.45, Test_accy 87.24:  45%|████▌     | 9/20 [24:58<27:47, 151.55s/it]
Task 4, Epoch 10/20 => Loss 0.272, Train_accy 92.45, Test_accy 87.24:  50%|█████     | 10/20 [24:58<24:59, 149.96s/it]
Task 4, Epoch 11/20 => Loss 0.259, Train_accy 92.99, Test_accy 87.46:  50%|█████     | 10/20 [27:30<24:59, 149.96s/it]
Task 4, Epoch 11/20 => Loss 0.259, Train_accy 92.99, Test_accy 87.46:  55%|█████▌    | 11/20 [27:30<22:34, 150.51s/it]
Task 4, Epoch 12/20 => Loss 0.253, Train_accy 92.77, Test_accy 88.61:  55%|█████▌    | 11/20 [29:56<22:34, 150.51s/it]
Task 4, Epoch 12/20 => Loss 0.253, Train_accy 92.77, Test_accy 88.61:  60%|██████    | 12/20 [29:56<19:52, 149.12s/it]
Task 4, Epoch 13/20 => Loss 0.245, Train_accy 93.16, Test_accy 88.24:  60%|██████    | 12/20 [32:24<19:52, 149.12s/it]
Task 4, Epoch 13/20 => Loss 0.245, Train_accy 93.16, Test_accy 88.24:  65%|██████▌   | 13/20 [32:24<17:20, 148.63s/it]
Task 4, Epoch 14/20 => Loss 0.233, Train_accy 93.38, Test_accy 88.45:  65%|██████▌   | 13/20 [34:51<17:20, 148.63s/it]
Task 4, Epoch 14/20 => Loss 0.233, Train_accy 93.38, Test_accy 88.45:  70%|███████   | 14/20 [34:51<14:49, 148.19s/it]
Task 4, Epoch 15/20 => Loss 0.241, Train_accy 93.28, Test_accy 88.85:  70%|███████   | 14/20 [37:20<14:49, 148.19s/it]
Task 4, Epoch 15/20 => Loss 0.241, Train_accy 93.28, Test_accy 88.85:  75%|███████▌  | 15/20 [37:20<12:21, 148.39s/it]
Task 4, Epoch 16/20 => Loss 0.236, Train_accy 93.26, Test_accy 89.04:  75%|███████▌  | 15/20 [39:49<12:21, 148.39s/it]
Task 4, Epoch 16/20 => Loss 0.236, Train_accy 93.26, Test_accy 89.04:  80%|████████  | 16/20 [39:49<09:55, 148.83s/it]
Task 4, Epoch 17/20 => Loss 0.225, Train_accy 93.66, Test_accy 87.90:  80%|████████  | 16/20 [42:18<09:55, 148.83s/it]
Task 4, Epoch 17/20 => Loss 0.225, Train_accy 93.66, Test_accy 87.90:  85%|████████▌ | 17/20 [42:18<07:26, 148.68s/it]
Task 4, Epoch 18/20 => Loss 0.214, Train_accy 93.98, Test_accy 88.40:  85%|████████▌ | 17/20 [44:44<07:26, 148.68s/it]
Task 4, Epoch 18/20 => Loss 0.214, Train_accy 93.98, Test_accy 88.40:  90%|█████████ | 18/20 [44:44<04:55, 147.96s/it]
Task 4, Epoch 19/20 => Loss 0.225, Train_accy 93.84, Test_accy 88.41:  90%|█████████ | 18/20 [47:11<04:55, 147.96s/it]
Task 4, Epoch 19/20 => Loss 0.225, Train_accy 93.84, Test_accy 88.41:  95%|█████████▌| 19/20 [47:11<02:27, 147.53s/it]
Task 4, Epoch 20/20 => Loss 0.224, Train_accy 93.77, Test_accy 88.59:  95%|█████████▌| 19/20 [49:39<02:27, 147.53s/it]
Task 4, Epoch 20/20 => Loss 0.224, Train_accy 93.77, Test_accy 88.59: 100%|██████████| 20/20 [49:39<00:00, 147.70s/it]
Task 4, Epoch 20/20 => Loss 0.224, Train_accy 93.77, Test_accy 88.59: 100%|██████████| 20/20 [49:39<00:00, 148.96s/it]2023-11-10 03:41:07,564 [prefix_prompt_tuning.py] => Task 4, Epoch 20/20 => Loss 0.224, Train_accy 93.77, Test_accy 88.59

2023-11-10 03:45:09,577 [trainer.py] => CNN: {'total': 90.35, '00-49': 90.35, 'old': 90.35, 'new': nan}
2023-11-10 03:45:09,577 [trainer.py] => CNN top1 curve: [87.53, 87.06, 88.2, 88.19, 90.35]
2023-11-10 03:45:09,578 [trainer.py] => All params: 149947393
2023-11-10 03:45:09,581 [trainer.py] => Trainable params: 269312
2023-11-10 03:45:09,581 [prefix_prompt_tuning.py] => Learning on 250-300
/vepfs/aminer_rec/algorithm/domain_increment/utils/toolkit.py:84: RuntimeWarning: invalid value encountered in long_scalars
  all_acc['new'] = np.around(((y_pred[idxes]%class_num) == (y_true[idxes]%class_num)).sum()*100 / len(idxes), decimals=2)
Parameters to be updated: {'classifier_pool.5.ctx', 'share_prompt.weight', 'prefix_prompt.e_p_10', 'prefix_prompt.e_p_0', 'prefix_prompt.e_p_9'},count:269312

  0%|          | 0/20 [00:00<?, ?it/s]
Task 5, Epoch 1/20 => Loss 1.721, Train_accy 40.77, Test_accy 64.84:   0%|          | 0/20 [02:25<?, ?it/s]
Task 5, Epoch 1/20 => Loss 1.721, Train_accy 40.77, Test_accy 64.84:   5%|▌         | 1/20 [02:25<46:13, 145.98s/it]
Task 5, Epoch 2/20 => Loss 0.779, Train_accy 77.72, Test_accy 80.00:   5%|▌         | 1/20 [04:54<46:13, 145.98s/it]
Task 5, Epoch 2/20 => Loss 0.779, Train_accy 77.72, Test_accy 80.00:  10%|█         | 2/20 [04:54<44:13, 147.42s/it]
Task 5, Epoch 3/20 => Loss 0.546, Train_accy 84.86, Test_accy 81.98:  10%|█         | 2/20 [07:20<44:13, 147.42s/it]
Task 5, Epoch 3/20 => Loss 0.546, Train_accy 84.86, Test_accy 81.98:  15%|█▌        | 3/20 [07:20<41:34, 146.72s/it]
Task 5, Epoch 4/20 => Loss 0.481, Train_accy 86.42, Test_accy 84.70:  15%|█▌        | 3/20 [09:46<41:34, 146.72s/it]
Task 5, Epoch 4/20 => Loss 0.481, Train_accy 86.42, Test_accy 84.70:  20%|██        | 4/20 [09:46<39:01, 146.36s/it]
Task 5, Epoch 5/20 => Loss 0.420, Train_accy 88.06, Test_accy 81.86:  20%|██        | 4/20 [12:15<39:01, 146.36s/it]
Task 5, Epoch 5/20 => Loss 0.420, Train_accy 88.06, Test_accy 81.86:  25%|██▌       | 5/20 [12:15<36:52, 147.49s/it]
Task 5, Epoch 6/20 => Loss 0.395, Train_accy 89.02, Test_accy 84.14:  25%|██▌       | 5/20 [14:44<36:52, 147.49s/it]
Task 5, Epoch 6/20 => Loss 0.395, Train_accy 89.02, Test_accy 84.14:  30%|███       | 6/20 [14:44<34:32, 148.07s/it]
Task 5, Epoch 7/20 => Loss 0.381, Train_accy 89.38, Test_accy 84.78:  30%|███       | 6/20 [17:10<34:32, 148.07s/it]
Task 5, Epoch 7/20 => Loss 0.381, Train_accy 89.38, Test_accy 84.78:  35%|███▌      | 7/20 [17:10<31:53, 147.16s/it]
Task 5, Epoch 8/20 => Loss 0.366, Train_accy 89.81, Test_accy 85.47:  35%|███▌      | 7/20 [19:37<31:53, 147.16s/it]
Task 5, Epoch 8/20 => Loss 0.366, Train_accy 89.81, Test_accy 85.47:  40%|████      | 8/20 [19:37<29:27, 147.32s/it]
Task 5, Epoch 9/20 => Loss 0.330, Train_accy 90.81, Test_accy 84.48:  40%|████      | 8/20 [22:04<29:27, 147.32s/it]
Task 5, Epoch 9/20 => Loss 0.330, Train_accy 90.81, Test_accy 84.48:  45%|████▌     | 9/20 [22:04<26:57, 147.01s/it]
Task 5, Epoch 10/20 => Loss 0.329, Train_accy 90.78, Test_accy 86.92:  45%|████▌     | 9/20 [24:31<26:57, 147.01s/it]
Task 5, Epoch 10/20 => Loss 0.329, Train_accy 90.78, Test_accy 86.92:  50%|█████     | 10/20 [24:31<24:31, 147.18s/it]
Task 5, Epoch 11/20 => Loss 0.308, Train_accy 91.40, Test_accy 86.04:  50%|█████     | 10/20 [26:59<24:31, 147.18s/it]
Task 5, Epoch 11/20 => Loss 0.308, Train_accy 91.40, Test_accy 86.04:  55%|█████▌    | 11/20 [26:59<22:05, 147.29s/it]
Task 5, Epoch 12/20 => Loss 0.277, Train_accy 92.19, Test_accy 86.53:  55%|█████▌    | 11/20 [29:29<22:05, 147.29s/it]
Task 5, Epoch 12/20 => Loss 0.277, Train_accy 92.19, Test_accy 86.53:  60%|██████    | 12/20 [29:29<19:44, 148.07s/it]
Task 5, Epoch 13/20 => Loss 0.290, Train_accy 92.01, Test_accy 86.50:  60%|██████    | 12/20 [31:57<19:44, 148.07s/it]
Task 5, Epoch 13/20 => Loss 0.290, Train_accy 92.01, Test_accy 86.50:  65%|██████▌   | 13/20 [31:57<17:17, 148.28s/it]
Task 5, Epoch 14/20 => Loss 0.275, Train_accy 92.43, Test_accy 85.05:  65%|██████▌   | 13/20 [34:29<17:17, 148.28s/it]
Task 5, Epoch 14/20 => Loss 0.275, Train_accy 92.43, Test_accy 85.05:  70%|███████   | 14/20 [34:29<14:55, 149.21s/it]
Task 5, Epoch 15/20 => Loss 0.265, Train_accy 92.58, Test_accy 86.28:  70%|███████   | 14/20 [36:57<14:55, 149.21s/it]
Task 5, Epoch 15/20 => Loss 0.265, Train_accy 92.58, Test_accy 86.28:  75%|███████▌  | 15/20 [36:57<12:25, 149.04s/it]
Task 5, Epoch 16/20 => Loss 0.260, Train_accy 92.70, Test_accy 86.38:  75%|███████▌  | 15/20 [39:24<12:25, 149.04s/it]
Task 5, Epoch 16/20 => Loss 0.260, Train_accy 92.70, Test_accy 86.38:  80%|████████  | 16/20 [39:24<09:53, 148.28s/it]
Task 5, Epoch 17/20 => Loss 0.263, Train_accy 92.61, Test_accy 86.49:  80%|████████  | 16/20 [41:51<09:53, 148.28s/it]
Task 5, Epoch 17/20 => Loss 0.263, Train_accy 92.61, Test_accy 86.49:  85%|████████▌ | 17/20 [41:51<07:24, 148.06s/it]
Task 5, Epoch 18/20 => Loss 0.250, Train_accy 92.93, Test_accy 86.14:  85%|████████▌ | 17/20 [44:17<07:24, 148.06s/it]
Task 5, Epoch 18/20 => Loss 0.250, Train_accy 92.93, Test_accy 86.14:  90%|█████████ | 18/20 [44:17<04:54, 147.40s/it]
Task 5, Epoch 19/20 => Loss 0.256, Train_accy 92.81, Test_accy 86.45:  90%|█████████ | 18/20 [46:43<04:54, 147.40s/it]
Task 5, Epoch 19/20 => Loss 0.256, Train_accy 92.81, Test_accy 86.45:  95%|█████████▌| 19/20 [46:43<02:26, 146.87s/it]
Task 5, Epoch 20/20 => Loss 0.239, Train_accy 93.07, Test_accy 86.27:  95%|█████████▌| 19/20 [49:10<02:26, 146.87s/it]
Task 5, Epoch 20/20 => Loss 0.239, Train_accy 93.07, Test_accy 86.27: 100%|██████████| 20/20 [49:10<00:00, 146.96s/it]
Task 5, Epoch 20/20 => Loss 0.239, Train_accy 93.07, Test_accy 86.27: 100%|██████████| 20/20 [49:10<00:00, 147.53s/it]2023-11-10 04:34:21,983 [prefix_prompt_tuning.py] => Task 5, Epoch 20/20 => Loss 0.239, Train_accy 93.07, Test_accy 86.27

2023-11-10 04:38:12,477 [trainer.py] => CNN: {'total': 90.48, '00-49': 90.48, 'old': 90.48, 'new': nan}
2023-11-10 04:38:12,477 [trainer.py] => CNN top1 curve: [87.53, 87.06, 88.2, 88.19, 90.35, 90.48]
2023-11-10 04:38:12,478 [trainer.py] => All params: 149947393
2023-11-10 04:38:12,479 [trainer.py] => Trainable params: 269312
2023-11-10 04:38:12,479 [prefix_prompt_tuning.py] => Learning on 300-350
/vepfs/aminer_rec/algorithm/domain_increment/utils/toolkit.py:84: RuntimeWarning: invalid value encountered in long_scalars
  all_acc['new'] = np.around(((y_pred[idxes]%class_num) == (y_true[idxes]%class_num)).sum()*100 / len(idxes), decimals=2)
Parameters to be updated: {'share_prompt.weight', 'prefix_prompt.e_p_10', 'classifier_pool.6.ctx', 'prefix_prompt.e_p_0', 'prefix_prompt.e_p_9'},count:269312

  0%|          | 0/20 [00:00<?, ?it/s]
Task 6, Epoch 1/20 => Loss 1.439, Train_accy 52.61, Test_accy 70.47:   0%|          | 0/20 [02:22<?, ?it/s]
Task 6, Epoch 1/20 => Loss 1.439, Train_accy 52.61, Test_accy 70.47:   5%|▌         | 1/20 [02:22<45:04, 142.35s/it]
Task 6, Epoch 2/20 => Loss 0.581, Train_accy 84.13, Test_accy 78.53:   5%|▌         | 1/20 [04:51<45:04, 142.35s/it]
Task 6, Epoch 2/20 => Loss 0.581, Train_accy 84.13, Test_accy 78.53:  10%|█         | 2/20 [04:51<43:49, 146.11s/it]
Task 6, Epoch 3/20 => Loss 0.452, Train_accy 87.98, Test_accy 79.25:  10%|█         | 2/20 [07:19<43:49, 146.11s/it]
Task 6, Epoch 3/20 => Loss 0.452, Train_accy 87.98, Test_accy 79.25:  15%|█▌        | 3/20 [07:19<41:42, 147.21s/it]
Task 6, Epoch 4/20 => Loss 0.409, Train_accy 88.93, Test_accy 81.63:  15%|█▌        | 3/20 [09:49<41:42, 147.21s/it]
Task 6, Epoch 4/20 => Loss 0.409, Train_accy 88.93, Test_accy 81.63:  20%|██        | 4/20 [09:49<39:33, 148.33s/it]
Task 6, Epoch 5/20 => Loss 0.390, Train_accy 89.69, Test_accy 83.01:  20%|██        | 4/20 [12:15<39:33, 148.33s/it]
Task 6, Epoch 5/20 => Loss 0.390, Train_accy 89.69, Test_accy 83.01:  25%|██▌       | 5/20 [12:15<36:53, 147.56s/it]
Task 6, Epoch 6/20 => Loss 0.351, Train_accy 90.48, Test_accy 82.70:  25%|██▌       | 5/20 [14:43<36:53, 147.56s/it]
Task 6, Epoch 6/20 => Loss 0.351, Train_accy 90.48, Test_accy 82.70:  30%|███       | 6/20 [14:43<34:28, 147.75s/it]
Task 6, Epoch 7/20 => Loss 0.322, Train_accy 91.31, Test_accy 82.98:  30%|███       | 6/20 [17:11<34:28, 147.75s/it]
Task 6, Epoch 7/20 => Loss 0.322, Train_accy 91.31, Test_accy 82.98:  35%|███▌      | 7/20 [17:11<31:58, 147.54s/it]
Task 6, Epoch 8/20 => Loss 0.320, Train_accy 91.43, Test_accy 82.18:  35%|███▌      | 7/20 [19:38<31:58, 147.54s/it]
Task 6, Epoch 8/20 => Loss 0.320, Train_accy 91.43, Test_accy 82.18:  40%|████      | 8/20 [19:38<29:29, 147.49s/it]
Task 6, Epoch 9/20 => Loss 0.318, Train_accy 91.61, Test_accy 81.80:  40%|████      | 8/20 [22:08<29:29, 147.49s/it]
Task 6, Epoch 9/20 => Loss 0.318, Train_accy 91.61, Test_accy 81.80:  45%|████▌     | 9/20 [22:08<27:11, 148.28s/it]
Task 6, Epoch 10/20 => Loss 0.290, Train_accy 92.24, Test_accy 82.92:  45%|████▌     | 9/20 [24:37<27:11, 148.28s/it]
Task 6, Epoch 10/20 => Loss 0.290, Train_accy 92.24, Test_accy 82.92:  50%|█████     | 10/20 [24:37<24:44, 148.43s/it]
Task 6, Epoch 11/20 => Loss 0.285, Train_accy 92.26, Test_accy 83.19:  50%|█████     | 10/20 [27:06<24:44, 148.43s/it]
Task 6, Epoch 11/20 => Loss 0.285, Train_accy 92.26, Test_accy 83.19:  55%|█████▌    | 11/20 [27:06<22:18, 148.69s/it]
Task 6, Epoch 12/20 => Loss 0.277, Train_accy 92.47, Test_accy 84.51:  55%|█████▌    | 11/20 [29:35<22:18, 148.69s/it]
Task 6, Epoch 12/20 => Loss 0.277, Train_accy 92.47, Test_accy 84.51:  60%|██████    | 12/20 [29:35<19:50, 148.85s/it]
Task 6, Epoch 13/20 => Loss 0.260, Train_accy 93.16, Test_accy 84.26:  60%|██████    | 12/20 [32:06<19:50, 148.85s/it]
Task 6, Epoch 13/20 => Loss 0.260, Train_accy 93.16, Test_accy 84.26:  65%|██████▌   | 13/20 [32:06<17:26, 149.51s/it]
Task 6, Epoch 14/20 => Loss 0.253, Train_accy 93.19, Test_accy 84.01:  65%|██████▌   | 13/20 [34:39<17:26, 149.51s/it]
Task 6, Epoch 14/20 => Loss 0.253, Train_accy 93.19, Test_accy 84.01:  70%|███████   | 14/20 [34:39<15:03, 150.56s/it]
Task 6, Epoch 15/20 => Loss 0.242, Train_accy 93.47, Test_accy 84.21:  70%|███████   | 14/20 [37:09<15:03, 150.56s/it]
Task 6, Epoch 15/20 => Loss 0.242, Train_accy 93.47, Test_accy 84.21:  75%|███████▌  | 15/20 [37:10<12:32, 150.46s/it]
Task 6, Epoch 16/20 => Loss 0.257, Train_accy 93.18, Test_accy 84.40:  75%|███████▌  | 15/20 [39:45<12:32, 150.46s/it]
Task 6, Epoch 16/20 => Loss 0.257, Train_accy 93.18, Test_accy 84.40:  80%|████████  | 16/20 [39:45<10:08, 152.07s/it]
Task 6, Epoch 17/20 => Loss 0.238, Train_accy 93.48, Test_accy 84.49:  80%|████████  | 16/20 [42:22<10:08, 152.07s/it]
Task 6, Epoch 17/20 => Loss 0.238, Train_accy 93.48, Test_accy 84.49:  85%|████████▌ | 17/20 [42:22<07:40, 153.36s/it]
Task 6, Epoch 18/20 => Loss 0.225, Train_accy 93.86, Test_accy 84.51:  85%|████████▌ | 17/20 [44:55<07:40, 153.36s/it]
Task 6, Epoch 18/20 => Loss 0.225, Train_accy 93.86, Test_accy 84.51:  90%|█████████ | 18/20 [44:55<05:06, 153.45s/it]
Task 6, Epoch 19/20 => Loss 0.236, Train_accy 93.47, Test_accy 84.71:  90%|█████████ | 18/20 [47:27<05:06, 153.45s/it]
Task 6, Epoch 19/20 => Loss 0.236, Train_accy 93.47, Test_accy 84.71:  95%|█████████▌| 19/20 [47:27<02:32, 152.95s/it]
Task 6, Epoch 20/20 => Loss 0.232, Train_accy 93.69, Test_accy 84.71:  95%|█████████▌| 19/20 [49:58<02:32, 152.95s/it]
Task 6, Epoch 20/20 => Loss 0.232, Train_accy 93.69, Test_accy 84.71: 100%|██████████| 20/20 [49:58<00:00, 152.37s/it]
Task 6, Epoch 20/20 => Loss 0.232, Train_accy 93.69, Test_accy 84.71: 100%|██████████| 20/20 [49:58<00:00, 149.93s/it]2023-11-10 05:28:12,805 [prefix_prompt_tuning.py] => Task 6, Epoch 20/20 => Loss 0.232, Train_accy 93.69, Test_accy 84.71

2023-11-10 05:32:04,572 [trainer.py] => CNN: {'total': 90.4, '00-49': 90.4, 'old': 90.4, 'new': nan}
2023-11-10 05:32:04,573 [trainer.py] => CNN top1 curve: [87.53, 87.06, 88.2, 88.19, 90.35, 90.48, 90.4]
2023-11-10 05:32:04,574 [trainer.py] => All params: 149947393
2023-11-10 05:32:04,575 [trainer.py] => Trainable params: 269312
2023-11-10 05:32:04,575 [prefix_prompt_tuning.py] => Learning on 350-400
/vepfs/aminer_rec/algorithm/domain_increment/utils/toolkit.py:84: RuntimeWarning: invalid value encountered in long_scalars
  all_acc['new'] = np.around(((y_pred[idxes]%class_num) == (y_true[idxes]%class_num)).sum()*100 / len(idxes), decimals=2)
Parameters to be updated: {'share_prompt.weight', 'prefix_prompt.e_p_10', 'classifier_pool.7.ctx', 'prefix_prompt.e_p_0', 'prefix_prompt.e_p_9'},count:269312

  0%|          | 0/20 [00:00<?, ?it/s]
Task 7, Epoch 1/20 => Loss 1.683, Train_accy 41.04, Test_accy 64.00:   0%|          | 0/20 [02:23<?, ?it/s]
Task 7, Epoch 1/20 => Loss 1.683, Train_accy 41.04, Test_accy 64.00:   5%|▌         | 1/20 [02:23<45:23, 143.34s/it]
Task 7, Epoch 2/20 => Loss 0.755, Train_accy 78.74, Test_accy 77.29:   5%|▌         | 1/20 [04:51<45:23, 143.34s/it]
Task 7, Epoch 2/20 => Loss 0.755, Train_accy 78.74, Test_accy 77.29:  10%|█         | 2/20 [04:51<43:48, 146.05s/it]
Task 7, Epoch 3/20 => Loss 0.560, Train_accy 84.15, Test_accy 86.22:  10%|█         | 2/20 [07:21<43:48, 146.05s/it]
Task 7, Epoch 3/20 => Loss 0.560, Train_accy 84.15, Test_accy 86.22:  15%|█▌        | 3/20 [07:21<41:54, 147.90s/it]
Task 7, Epoch 4/20 => Loss 0.454, Train_accy 87.34, Test_accy 86.30:  15%|█▌        | 3/20 [09:49<41:54, 147.90s/it]
Task 7, Epoch 4/20 => Loss 0.454, Train_accy 87.34, Test_accy 86.30:  20%|██        | 4/20 [09:49<39:25, 147.85s/it]
Task 7, Epoch 5/20 => Loss 0.419, Train_accy 88.32, Test_accy 85.94:  20%|██        | 4/20 [12:16<39:25, 147.85s/it]
Task 7, Epoch 5/20 => Loss 0.419, Train_accy 88.32, Test_accy 85.94:  25%|██▌       | 5/20 [12:16<36:56, 147.76s/it]
Task 7, Epoch 6/20 => Loss 0.395, Train_accy 89.18, Test_accy 87.02:  25%|██▌       | 5/20 [14:44<36:56, 147.76s/it]
Task 7, Epoch 6/20 => Loss 0.395, Train_accy 89.18, Test_accy 87.02:  30%|███       | 6/20 [14:44<34:29, 147.81s/it]
Task 7, Epoch 7/20 => Loss 0.372, Train_accy 89.74, Test_accy 87.91:  30%|███       | 6/20 [17:11<34:29, 147.81s/it]
Task 7, Epoch 7/20 => Loss 0.372, Train_accy 89.74, Test_accy 87.91:  35%|███▌      | 7/20 [17:11<31:58, 147.60s/it]
Task 7, Epoch 8/20 => Loss 0.352, Train_accy 90.24, Test_accy 88.39:  35%|███▌      | 7/20 [19:40<31:58, 147.60s/it]
Task 7, Epoch 8/20 => Loss 0.352, Train_accy 90.24, Test_accy 88.39:  40%|████      | 8/20 [19:40<29:35, 147.97s/it]
Task 7, Epoch 9/20 => Loss 0.329, Train_accy 90.79, Test_accy 89.56:  40%|████      | 8/20 [22:06<29:35, 147.97s/it]
Task 7, Epoch 9/20 => Loss 0.329, Train_accy 90.79, Test_accy 89.56:  45%|████▌     | 9/20 [22:06<27:02, 147.47s/it]
Task 7, Epoch 10/20 => Loss 0.313, Train_accy 91.13, Test_accy 89.48:  45%|████▌     | 9/20 [24:35<27:02, 147.47s/it]
Task 7, Epoch 10/20 => Loss 0.313, Train_accy 91.13, Test_accy 89.48:  50%|█████     | 10/20 [24:35<24:38, 147.82s/it]
Task 7, Epoch 11/20 => Loss 0.305, Train_accy 91.25, Test_accy 89.55:  50%|█████     | 10/20 [27:04<24:38, 147.82s/it]
Task 7, Epoch 11/20 => Loss 0.305, Train_accy 91.25, Test_accy 89.55:  55%|█████▌    | 11/20 [27:04<22:13, 148.17s/it]
Task 7, Epoch 12/20 => Loss 0.295, Train_accy 91.64, Test_accy 89.74:  55%|█████▌    | 11/20 [29:34<22:13, 148.17s/it]
Task 7, Epoch 12/20 => Loss 0.295, Train_accy 91.64, Test_accy 89.74:  60%|██████    | 12/20 [29:34<19:50, 148.84s/it]
Task 7, Epoch 13/20 => Loss 0.287, Train_accy 91.94, Test_accy 89.77:  60%|██████    | 12/20 [32:02<19:50, 148.84s/it]
Task 7, Epoch 13/20 => Loss 0.287, Train_accy 91.94, Test_accy 89.77:  65%|██████▌   | 13/20 [32:02<17:18, 148.40s/it]
Task 7, Epoch 14/20 => Loss 0.278, Train_accy 92.44, Test_accy 90.40:  65%|██████▌   | 13/20 [34:30<17:18, 148.40s/it]
Task 7, Epoch 14/20 => Loss 0.278, Train_accy 92.44, Test_accy 90.40:  70%|███████   | 14/20 [34:30<14:49, 148.31s/it]
Task 7, Epoch 15/20 => Loss 0.271, Train_accy 92.60, Test_accy 89.84:  70%|███████   | 14/20 [36:59<14:49, 148.31s/it]
Task 7, Epoch 15/20 => Loss 0.271, Train_accy 92.60, Test_accy 89.84:  75%|███████▌  | 15/20 [36:59<12:22, 148.57s/it]
Task 7, Epoch 16/20 => Loss 0.277, Train_accy 92.19, Test_accy 90.71:  75%|███████▌  | 15/20 [39:27<12:22, 148.57s/it]
Task 7, Epoch 16/20 => Loss 0.277, Train_accy 92.19, Test_accy 90.71:  80%|████████  | 16/20 [39:27<09:54, 148.53s/it]
Task 7, Epoch 17/20 => Loss 0.250, Train_accy 92.98, Test_accy 90.09:  80%|████████  | 16/20 [41:54<09:54, 148.53s/it]
Task 7, Epoch 17/20 => Loss 0.250, Train_accy 92.98, Test_accy 90.09:  85%|████████▌ | 17/20 [41:54<07:24, 148.05s/it]
Task 7, Epoch 18/20 => Loss 0.250, Train_accy 93.21, Test_accy 90.23:  85%|████████▌ | 17/20 [44:21<07:24, 148.05s/it]
Task 7, Epoch 18/20 => Loss 0.250, Train_accy 93.21, Test_accy 90.23:  90%|█████████ | 18/20 [44:21<04:54, 147.49s/it]
Task 7, Epoch 19/20 => Loss 0.247, Train_accy 93.32, Test_accy 90.40:  90%|█████████ | 18/20 [46:47<04:54, 147.49s/it]
Task 7, Epoch 19/20 => Loss 0.247, Train_accy 93.32, Test_accy 90.40:  95%|█████████▌| 19/20 [46:47<02:27, 147.11s/it]
Task 7, Epoch 20/20 => Loss 0.243, Train_accy 93.05, Test_accy 90.33:  95%|█████████▌| 19/20 [49:13<02:27, 147.11s/it]
Task 7, Epoch 20/20 => Loss 0.243, Train_accy 93.05, Test_accy 90.33: 100%|██████████| 20/20 [49:13<00:00, 146.95s/it]
Task 7, Epoch 20/20 => Loss 0.243, Train_accy 93.05, Test_accy 90.33: 100%|██████████| 20/20 [49:13<00:00, 147.70s/it]2023-11-10 06:21:20,157 [prefix_prompt_tuning.py] => Task 7, Epoch 20/20 => Loss 0.243, Train_accy 93.05, Test_accy 90.33

2023-11-10 06:25:07,479 [trainer.py] => CNN: {'total': 90.67, '00-49': 90.67, 'old': 90.67, 'new': nan}
2023-11-10 06:25:07,481 [trainer.py] => CNN top1 curve: [87.53, 87.06, 88.2, 88.19, 90.35, 90.48, 90.4, 90.67]
/vepfs/aminer_rec/algorithm/domain_increment/utils/toolkit.py:84: RuntimeWarning: invalid value encountered in long_scalars
  all_acc['new'] = np.around(((y_pred[idxes]%class_num) == (y_true[idxes]%class_num)).sum()*100 / len(idxes), decimals=2)
